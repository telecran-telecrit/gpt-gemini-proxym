app = 'gemini-openai-proxy'
primary_region = 'lax'

[build]
dockerfile = 'docker/bun.Dockerfile'

[http_service]
internal_port = 3040
force_https = true
auto_stop_machines = "suspend"
auto_start_machines = true
min_machines_running = 0
processes = ['app']

[http_service.concurrency]
type = 'requests'
hard_limit = 250
soft_limit = 200

[[vm]]
memory = '256MB'
cpu_kind = 'shared'
cpus = 1
